# text_generator.py

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Step 1: Prepare the Dataset
quotes = [
    "The best is yet to come.",
    "Keep your face always toward the sunshine.",
    "You are enough just as you are.",
    "Believe you can and you're halfway there.",
    "Happiness is not by chance, but by choice."
]

# Create a single string from the quotes
text = ' '.join(quotes)

# Create a set of unique characters and mapping to integers
chars = sorted(list(set(text)))
char_to_idx = {char: idx for idx, char in enumerate(chars)}
idx_to_char = {idx: char for idx, char in enumerate(chars)}

# Prepare input and output sequences
seq_length = 40  # Length of each input sequence
step = 3        # Step size for moving through the text

sentences = []
next_chars = []

for i in range(0, len(text) - seq_length, step):
    sentences.append(text[i:i + seq_length])
    next_chars.append(text[i + seq_length])

print(f"Number of sequences: {len(sentences)}")

# Step 2: Vectorize the Data
X = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)

for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        X[i, t, char_to_idx[char]] = 1
    y[i, char_to_idx[next_chars[i]]] = 1

# Step 3: Build the RNN Model
model = keras.Sequential()
model.add(layers.SimpleRNN(128, input_shape=(seq_length, len(chars))))
model.add(layers.Dense(len(chars), activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam')

# Step 4: Train the Model
history = model.fit(X, y, batch_size=32, epochs=50)

# Step 5: Generate Text
def generate_text(seed, length=100):
    generated = ''
    sentence = seed

    for _ in range(length):
        x_pred = np.zeros((1, seq_length, len(chars)))
        for t, char in enumerate(sentence):
            x_pred[0, t, char_to_idx[char]] = 1.

        preds = model.predict(x_pred, verbose=0)[0]
        next_index = np.random.choice(len(chars), p=preds)
        next_char = idx_to_char[next_index]

        generated += next_char
        sentence = sentence[1:] + next_char

    return generated

# Generate some text starting with a seed phrase
seed_text = "The best"
print("Generated Text:")
print(generate_text(seed_text))

# Step 6: Visualize Training History (Optional)
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.show()
